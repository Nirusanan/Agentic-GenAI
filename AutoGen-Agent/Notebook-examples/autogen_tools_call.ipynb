{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Tools are pre-defined functions that agents can use. Agents can call tools to perform actions, such as searching the web, performing calculations, reading files, or calling remote APIs."
      ],
      "metadata": {
        "id": "ytERkIrelJLS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6N6S3FORtKK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d270ab4-a95c-4a2e-9164-5988982cc572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/382.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.2/382.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/147.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.9/313.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -q \"autogen-agentchat==0.2.39\" \"groq==0.13.0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import autogen\n",
        "from autogen import AssistantAgent, ConversableAgent\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "f3vSe7xiyfOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eba9193-235c-4533-956f-c47d878c7376"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get('GROQ_API_KEY')\n",
        "model = \"llama-3.3-70b-versatile\""
      ],
      "metadata": {
        "id": "rlWqet2EypRy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_config = {\n",
        "    \"model\": model,\n",
        "    \"api_key\": api_key,\n",
        "    \"api_type\": \"groq\",\n",
        "    }"
      ],
      "metadata": {
        "id": "lcH_VC_Vyq57"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, Literal\n",
        "import os\n",
        "from autogen import ConversableAgent"
      ],
      "metadata": {
        "id": "y06_RQbRzKjS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Literal is used to specify that the Operator type\n",
        "Operator = Literal[\"+\", \"-\", \"*\", \"/\"]\n",
        "\n",
        "\n",
        "# The Annotated type provides additional metadata. Metadata can be used by external tools for validation\n",
        "def calculator(a: int, b: int, operator: Annotated[Operator, \"operator\"]) -> int:\n",
        "    if operator == \"+\":\n",
        "        return a + b\n",
        "    elif operator == \"-\":\n",
        "        return a - b\n",
        "    elif operator == \"*\":\n",
        "        return a * b\n",
        "    elif operator == \"/\":\n",
        "        return int(a / b)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid operator\")"
      ],
      "metadata": {
        "id": "d_6uzYemzLKV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = ConversableAgent(\n",
        "    name=\"Assistant\",\n",
        "    system_message=\"You are a helpful AI assistant. \"\n",
        "    \"You can help with simple calculations. \"\n",
        "    \"Return 'TERMINATE' when the task is done.\",\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "\n",
        "# User proxy agent is used for interacting with the assistant agent and executes tool calls.\n",
        "user_proxy = ConversableAgent(\n",
        "    name=\"User\",\n",
        "    llm_config=False,\n",
        "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ],
      "metadata": {
        "id": "FvDQaRMbzfPY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import register_function\n",
        "\n",
        "# Register the calculator function to the two agents.\n",
        "register_function(\n",
        "    calculator,\n",
        "    caller=assistant,  # The assistant agent can suggest calls to the calculator.\n",
        "    executor=user_proxy,  # The user proxy agent can execute the calculator calls.\n",
        "    name=\"calculator\",  # By default, the function name is used as the tool name.\n",
        "    description=\"A simple calculator\",\n",
        ")"
      ],
      "metadata": {
        "id": "uOaQLACa0HKa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_result = user_proxy.initiate_chat(assistant, message=\"What is (44232 + 13312 / (232 - 32)) * 5?\")"
      ],
      "metadata": {
        "id": "rupAwgj30dGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1041fbb-b836-4013-da50-577f2beb93fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User (to Assistant):\n",
            "\n",
            "What is (44232 + 13312 / (232 - 32)) * 5?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "Assistant (to User):\n",
            "\n",
            "***** Suggested tool call (call_ncwx): calculator *****\n",
            "Arguments: \n",
            "{\"a\": 232, \"b\": 32, \"operator\": \"-\"}\n",
            "*******************************************************\n",
            "***** Suggested tool call (call_as2c): calculator *****\n",
            "Arguments: \n",
            "{\"a\": 13312, \"b\": 200, \"operator\": \"/\"}\n",
            "*******************************************************\n",
            "***** Suggested tool call (call_7vej): calculator *****\n",
            "Arguments: \n",
            "{\"a\": 44232, \"b\": 66, \"operator\": \"+\"}\n",
            "*******************************************************\n",
            "***** Suggested tool call (call_qs9f): calculator *****\n",
            "Arguments: \n",
            "{\"a\": 44298, \"b\": 5, \"operator\": \"*\"}\n",
            "*******************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION calculator...\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION calculator...\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION calculator...\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION calculator...\n",
            "User (to Assistant):\n",
            "\n",
            "User (to Assistant):\n",
            "\n",
            "***** Response from calling tool (call_ncwx) *****\n",
            "200\n",
            "**************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "User (to Assistant):\n",
            "\n",
            "***** Response from calling tool (call_as2c) *****\n",
            "66\n",
            "**************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "User (to Assistant):\n",
            "\n",
            "***** Response from calling tool (call_7vej) *****\n",
            "44298\n",
            "**************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "User (to Assistant):\n",
            "\n",
            "***** Response from calling tool (call_qs9f) *****\n",
            "221490\n",
            "**************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autogen/oai/groq.py:280: UserWarning: Cost calculation not available for model llama-3.3-70b-versatile\n",
            "  warnings.warn(f\"Cost calculation not available for model {model}\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant (to User):\n",
            "\n",
            "The final answer is 221490. \n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  `user_proxy` agent execute the function calling --> return int\n",
        "*  `assistant` agent takes the arguments and suggests tools using LLM\n",
        "\n"
      ],
      "metadata": {
        "id": "M-LZWDPsduLt"
      }
    }
  ]
}