{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rZcOHESHJXH"
      },
      "source": [
        "Document loaders provide a **standard interface** for reading data from different sources into LangChain‚Äôs Document format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv-xONTXtGBI"
      },
      "outputs": [],
      "source": [
        "!pip install -q \"langchain==0.3.27\" \"langchain-community==0.3.31\" pypdf pymupdf unstructured libmagic python-magic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csfWpVIjsYnA"
      },
      "source": [
        "### text loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bYpU_oSQtqcQ"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JIA8sxytyDe",
        "outputId": "c1df8cfc-2b83-434c-f96f-25ef976552ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(metadata={'source': '/content/gold.txt'}, page_content='The sharp rally comes as markets digest signs that the Federal Reserve may soon shift its policy stance. With inflation concerns easing but job market risks rising, traders are betting heavily on a 25-basis-point rate cut in both October and December. Those expectations have weakened the dollar, boosted commodities, and made gold more appealing to investors seeking stability over volatility.\\n\\nAt the same time, the ongoing U.S. government shutdown, now stretching into its 13th day, has raised fears about political gridlock and fiscal disruption. The combination of economic uncertainty and political strain has amplified investors‚Äô preference for hard assets like gold and silver. Safe-haven buying has surged across global markets, from New York to Singapore.\\n\\nThe precious metals rally isn‚Äôt just about policy expectations. Renewed tensions between Washington and Beijing over trade, technology, and market access have resurfaced at a delicate time for both economies. Reports of a possible meeting between President Donald Trump and Chinese President Xi Jinping have fueled speculation, but until a breakthrough emerges, markets remain nervous.\\n\\nPhiladelphia Fed chief Anna Paulson highlighted growing labor market risks. Traders now price in a 25-basis-point Fed rate cut in October (99% chance) and December (94% chance). Meanwhile, geopolitical concerns, including potential talks between President Trump and Chinese President Xi Jinping, are keeping investors cautious. The U.S. government shutdown, now in its 13th day, adds to the uncertainty.\\n\\nBank of America raised its 2026 gold forecast to $5,000 per ounce. Analysts cite inflation concerns and continued rate-cut expectations. Silver is projected to test $65 per ounce, though BofA warns of possible near-term corrections. Other metals also gained, with platinum at $1,677 (+1.9%) and palladium at $1,505.75 (+2.1%).\\n\\nIn this climate, gold has reasserted its historic role as a protector of wealth. The year-to-date gain of 57% underlines how investors are positioning themselves ahead of potential market turbulence. Analysts say the metal‚Äôs climb reflects deep unease about the global economy‚Äôs direction, even as equities recover.\\n')]\n"
          ]
        }
      ],
      "source": [
        "loader = TextLoader(\"/content/gold.txt\")\n",
        "data = loader.load()\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1YCuqrhJ4Ky"
      },
      "source": [
        "### load PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_-3ZlOMGC27",
        "outputId": "a0585559-aecc-4cd7-cccf-12ba57203f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "file_path = \"/content/Transformer archtecture.pdf\"\n",
        "loader = PyPDFLoader(file_path)\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeRWgO4cJ7mm",
        "outputId": "2e6b8f19-a418-4804-fcae-f6f1994c89c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'producer': 'Skia/PDF m139 Google Docs Renderer',\n",
              " 'creator': '',\n",
              " 'creationdate': '',\n",
              " 'source': '/content/Transformer archtecture.pdf',\n",
              " 'file_path': '/content/Transformer archtecture.pdf',\n",
              " 'total_pages': 14,\n",
              " 'format': 'PDF 1.4',\n",
              " 'title': 'Transformer architecture Details',\n",
              " 'author': '',\n",
              " 'subject': '',\n",
              " 'keywords': '',\n",
              " 'moddate': '',\n",
              " 'trapped': '',\n",
              " 'modDate': '',\n",
              " 'creationDate': '',\n",
              " 'page': 0}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "file_path = \"/content/Transformer archtecture.pdf\"\n",
        "loader = PyMuPDFLoader(file_path)\n",
        "\n",
        "docs = loader.load()\n",
        "docs[0].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI_r1Me0LNxv"
      },
      "source": [
        "1.   PyPDFLoader - Extract Images\n",
        "2.   PyMuPDFLoader  - Extract Images, Extract Tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLqIeUewUG_A"
      },
      "source": [
        "### UnstructuredURLLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrZRgVOJh_Eb"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "\n",
        "loader = UnstructuredURLLoader(urls = [\n",
        "    \"https://huggingface.co/blog/swift-transformers\",\n",
        "    \"https://huggingface.co/blog/openvino-vlm\",\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xam1r0coomz7"
      },
      "outputs": [],
      "source": [
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "OjyNLOeTozeW",
        "outputId": "7def5d1d-045f-41dd-b645-872a0f8366cd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Back to Articles\\n\\nSwift Transformers Reaches 1.0 ‚Äì and Looks to the Future\\n\\nPublished September 26, 2025\\n\\nUpdate on GitHub\\n\\nUpvote\\n\\n30\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPedro Cuenca\\'s avatar\\n\\nPedro Cuenca\\n\\npcuenq\\n\\nChristopher Fleetwood\\'s avatar\\n\\nChristopher Fleetwood\\n\\nFL33TW00D-HF\\n\\nMattt\\'s avatar\\n\\nMattt\\n\\nmattt\\n\\nVaibhav Srivastav\\'s avatar\\n\\nVaibhav Srivastav\\n\\nreach-vb\\n\\nWe released swift-transformers two years ago (!) with the goal to support Apple developers and help them integrate local LLMs in their apps. A lot has changed since then (MLX and chat templates did not exist!), and we‚Äôve learned how the community is actually using the library.\\n\\nWe want to double down on the use cases that provide most benefits to the community, and lay out the foundations for the future. Spoiler alert: after this release, we‚Äôll focus a lot on MLX and agentic use cases üöÄ\\n\\nWhat is swift-transformers\\n\\nswift-transformers is a Swift library that aims to reduce the friction for developers that want to work with local models on Apple Silicon platforms, including iPhones. It includes the missing pieces that are not provided by Core ML or MLX alone, but that are required to work with local inference. Namely, it provides the following components:\\n\\nTokenizers. Preparing inputs for a language model is surprisingly complex. We\\'ve built a lot of experience with our tokenizers Python and Rust libraries, which are foundational to the AI ecosystem. We wanted to bring the same performant, ergonomic experience to Swift. The Swift version of Tokenizers should handle everything for you, including chat templates and agentic use!\\n\\nHub. This is an interface to the Hugging Face Hub, where all open models are available. It allows you to download models from the Hub and cache them locally, and supports background resumable downloads, model updates, offline mode. It contains a subset of the functionality provided by the Python and JavaScript libraries, focused on the tasks that Apple developers need the most (i.e., uploads are not supported).\\n\\nModels and Generation. These are wrappers for LLMs converted to the Core ML format. Converting them is out of the scope of the library (but we have some guides). Once they are converted, these modules make it easy to run inference with them.\\n\\nHow is the community using it\\n\\nMost of the time people use the Tokenizers or Hub modules, and frequently both. Some notable projects that rely on swift-transformers include:\\n\\nmlx-swift-examples, by Apple. It‚Äôs, in fact, not just a collection of examples, but a list of libraries you can use to run various types of models using MLX, including LLMs and VLMs (vision-language models). It‚Äôs kind of our Models and Generation libraries but for MLX instead of Core ML ‚Äì and it supports many more model types like embedders or Stable Diffusion.\\n\\nWhisperKit, by argmax. Open Source ASR (speech recognition) framework, super heavily optimized for Apple Silicon. It relies on our Hub and Tokenizers modules.\\n\\nFastVLM, by Apple, and many other app demos, such as our own SmolVLM2 native app.\\n\\nWhat changes with v1.0\\n\\nVersion 1.0 signals stability in the package. Developers are building apps on swift-transformers, and this first major release recognizes those use cases and brings the version number in line with that reality. It also provides the foundation on which to iterate with the community to build the next set of features. These are some of our preferred updates:\\n\\nTokenizers and Hub are now first-class, top-level modules. Before 1.0, you had to depend on and import the full package, whereas now you can just pick Tokenizers, for instance.\\n\\nSpeaking of Jinja, we are super proud to announce that we have collaborated with John Mai (X) to create the next version of his excellent Swift Jinja library. John‚Äôs work has been crucial for the community: he single-handedly took on the task to provide a solid chat template library that could grow as templates became more and more complex. The new version is a couple orders of magnitude faster (no kidding), and lives here as swift-jinja.\\n\\nTo further reduce the load imposed on downstream users, we have removed our example CLI targets and the swift-argument-parser dependency, which in turn prevents version conflicts for projects that already use it.\\n\\nThanks to contributions by Apple, we have adopted Modern Core ML APIs with support for stateful models (for easier KV-caching) and expressive MLTensor APIs ‚Äì this removes thousands of lines of custom tensor operations and math code.\\n\\nLots of additional cruft removed and API surface reduced to reduce cognitive load and iterate faster.\\n\\nTests are better, faster, stronger.\\n\\nDocumentation comments have been added to public APIs.\\n\\nSwift 6 is fully supported.\\n\\nVersion 1.0 comes with breaking API changes. However, we don‚Äôt expect major problems if you are a user of Tokenizers or Hub. If you use the Core ML components of the library, please get in touch so we can support you during transition. We‚Äôll prepare a migration guide and add it to the documentation.\\n\\nUsage Examples\\n\\nHere\\'s how to use Tokenizers to format tool calling input for an LLM:\\n\\nimport Tokenizers\\n\\nlet tokenizer = try await AutoTokenizer.from(pretrained: \"mlx-community/Qwen2.5-7B-Instruct-4bit\")\\n\\nlet weatherTool = [\\n    \"type\": \"function\",\\n    \"function\": [\\n        \"name\": \"get_current_weather\",\\n        \"description\": \"Get the current weather in a given location\",\\n        \"parameters\": [\\n            \"type\": \"object\",\\n            \"properties\": [\"location\": [\"type\": \"string\", \"description\": \"City and state\"]],\\n            \"required\": [\"location\"]\\n        ]\\n    ]\\n]\\n\\nlet tokens = try tokenizer.applyChatTemplate(\\n    messages: [[\"role\": \"user\", \"content\": \"What\\'s the weather in Paris?\"]],\\n    tools: [weatherTool]\\n)\\n\\nFor additional examples, please check this section in the README and the Examples folder.\\n\\nWhat comes next\\n\\nHonestly, we don‚Äôt know. We do know that we are super interested in exploring MLX, because that‚Äôs usually the current go-to approach for developers getting started with ML in native apps, and we want to help make the experience as seamless as possible. We are thinking along the lines of better integration with mlx-swift-examples for LLMs and VLMs, potentially through pre-processing and post-processing operations that developers encounter frequently.\\n\\nWe are also extremely excited about agentic use in general and MCP in particular. We think that exposure of system resources to local workflows would be üöÄ\\n\\nIf you want to follow along in this journey or want to share your ideas, please contact us through our social networks or the repo.\\n\\nWe couldn‚Äôt have done this without you ü´µ\\n\\nWe are immensely grateful to all the contributors and users of the library for your help and feedback. We love you all, and can\\'t wait to continue working with you to shape the future of on-device generation! ‚ù§Ô∏è\\n\\nMore Articles from our Blog\\n\\n\\n\\ncoremlapple\\n\\nSOTA OCR on-device with Core ML and dots.ocr\\n\\n\\n\\n\\n\\n39\\n\\nOctober 2, 2025\\n\\n\\n\\ncoremlguidellm\\n\\nWWDC 24: Running Mistral 7B with Core ML\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n62\\n\\nJuly 22, 2024\\n\\nCommunity\\n\\n\\n\\nJohnMai\\n\\n20 days ago\\n\\nMany thanks to the Hugging Face team for the recognition and for pushing the Swift ecosystem forward. It‚Äôs been an honor to contribute Swift Jinja to the community, and I look forward to building the future together!‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è\\n\\n\\n\\npcuenq\\n\\nArticle author 20 days ago\\n\\nIt\\'s a pleasure to work together @JohnMai !\\n\\n\\n\\nmikinyaa\\n\\n19 days ago\\n\\nCool to see üçé catching up\\n\\nSign up or log in to comment\\n\\nUpvote\\n\\n30\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1RhtrUoUjAY"
      },
      "source": [
        "### Text spliter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DkTrJW7VzuD"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"To showcase the real-world potential, we deployed our optimized setup with the smolagents library. With this integration, developers can plug in Qwen3-8B (paired with our pruned draft) to build agents that call APIs and external tools, write and execute code, handle long-context reasoning and run efficiently on Intel¬Æ Core‚Ñ¢ Ultra. The benefits aren‚Äôt limited to Hugging Face, this model pairing can also be used seamlessly with frameworks like AutoGen or QwenAgent, further strengthening the agentic ecosystem.\n",
        "In our demo, we assigned the accelerated Qwen3-based agent a task: Summarize the key features of the Qwen3 model series and present them in a slide deck.\n",
        "\n",
        "Here‚Äôs how it worked: 1. The agent used a web search tool to gather up-to-date information. 2. It then switched to the Python interpreter to generate slides with the python-pptx library. This simple workflow highlights just a fraction of the possibilities unlocked when accelerated Qwen3 models meet frameworks like smolagents, bringing practical, efficient AI agents to life on AI PC. Try it here.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edhx3byEwATC"
      },
      "source": [
        "CharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0xsZwzjUloW",
        "outputId": "4a5e913e-2ec9-4d58-b945-79904a770e5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 666, which is longer than the specified 200\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\\n\",\n",
        "    chunk_size = 200,\n",
        "    chunk_overlap = 0\n",
        ")\n",
        "\n",
        "chunks = splitter.split_text(text)\n",
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdgrZTJKWtWK",
        "outputId": "bb7107a5-79e2-4556-b2c5-8d275bf38244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "666\n",
            "398\n"
          ]
        }
      ],
      "source": [
        "for chunk in chunks:\n",
        "  print(len(chunk))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkpVSYpmwCPm"
      },
      "source": [
        "RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2mENyvtvkwL",
        "outputId": "ff1333f6-33bd-4561-c928-ffa7e7afedb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators = [\"\\n\\n\", \"\\n\", \" \"],\n",
        "    chunk_size = 200,\n",
        "    chunk_overlap = 0\n",
        "\n",
        ")\n",
        "\n",
        "chunks = r_splitter.split_text(text)\n",
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dHfA2EBw8DM",
        "outputId": "2bbb3952-ba3d-4680-d76c-52aec7033b13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n",
            "199\n",
            "111\n",
            "153\n",
            "198\n",
            "199\n"
          ]
        }
      ],
      "source": [
        "for chunk in chunks:\n",
        "  print(len(chunk))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
